{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"JVM","slug":"JVM","date":"2021-09-03T02:04:17.000Z","updated":"2021-09-03T02:05:17.026Z","comments":true,"path":"2021/09/03/JVM/","link":"","permalink":"http://example.com/2021/09/03/JVM/","excerpt":"","text":"JVM GC相关Java垃圾回收机制 当对象没有被其他对象引用的时候，则会判定为垃圾 判定对象是否为垃圾的算法：判断对象的引用数量 通过判断对象的引用数量来决定对象是否可以被回收 每个对象实例都会有一个引用计数器，被引用则+1，完成引用则-1 优点：执行效率高，程序执行受影响较小 缺点：无法检测出循环引用的情况，导致内存泄漏 可达性分析算法 通过判断对象的引用链是否可达来决定对象是否可以被回收，通过一系列的GC Root节点为起点进行搜索，如果一个对象不存在所有的引用链上，则是不可达的。 可以作为GC Root的对象： 虚拟机栈中引用的对象(栈帧中的本地变量表) 方法区中的常用引用的对象 方法区中的类静态属性引用的对象 本地方法栈中JNI（Native方法）的引用对象 活跃线程的引用对象 Java垃圾回收之回收算法标记-清除算法(Mark and Sweep)标记：从集合进行扫描，对根集合进行扫描，对存活的对象进行标记 清除：对堆内存从头到尾进行线性遍历，回收不可达对象内存 缺点：容易产生碎片化，因为标记清楚时不会对对象进行移动等操作，可能会导致在后期碎片化严重时，无法分配空间 复制算法（Copying） 分为对象面和空闲面 对象在对象面上创建 存活的对象被从对象面复制到空闲面 将对象面的所有对象内存清除 适合对象存活率低的场景，比如jvm的年轻代，因为会将对象进行移动，也不会产生碎片化的情况 标记-整理算法（Compacting） 标记：从根集合进行扫描，对存活的对象进行标记 清除：移动所有存活的对象，且按照内存地址次序依次排列，然后将末端内存地址以后的内存全部回收。 分代收集算法（Generational Collector） 垃圾回收算法的组合拳 按照对象生命周期的不同划分区域以采用不同的垃圾回收算法 目的：提高JVM的回收效率 GC的分类 Minor GC Full GC 年轻代：尽可能快速地收集那些生命周期短的现象 Eden区 两个Survivor区 Java垃圾回收之新生代垃圾收集器Stop-the-World JVM由于要执行GC而停止了应用程序的执行 任何一种GC算法中都会发生 多数GC优化通过减少Stop-the-World发生的时间来提高程序性能 虚引用不能通过Reference的get()是不是null来判断是否被回收，只能通过引用队列的方式进行判断，因此虚引用的构造函数是有引用队列参数的。 引用队列的使用示例：1234567891011121314151617public class NormalObject &#123; private String name; public NormalObject(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; @Override protected void finalize() throws Throwable &#123; System.out.println(&quot;NormalObj执行finalize()&quot;); &#125;&#125; 1234567891011121314151617public class WeakNormalObjectReference extends WeakReference&lt;NormalObject&gt; &#123; private String name; public WeakNormalObjectReference(NormalObject referent, ReferenceQueue&lt;? super NormalObject&gt; q) &#123; super(referent, q); this.name = referent.getName(); &#125; public String getName() &#123; return name; &#125; @Override protected void finalize() throws Throwable &#123; System.out.println(&quot;WeakNormalObjectReference执行finalize() name: &quot; + this.name); &#125;&#125; 123456789101112131415161718public class WeakRefTest &#123; public static void main(String[] args) throws InterruptedException &#123; ReferenceQueue&lt;NormalObject&gt; referenceQueue = new ReferenceQueue&lt;&gt;(); List&lt;WeakReference&lt;NormalObject&gt;&gt; weakObjList = new ArrayList&lt;&gt;(); weakObjList.add(new WeakNormalObjectReference(new NormalObject(&quot;huang&quot;), referenceQueue)); weakObjList.add(new WeakNormalObjectReference(new NormalObject(&quot;qi&quot;), referenceQueue)); weakObjList.add(new WeakNormalObjectReference(new NormalObject(&quot;chang&quot;), referenceQueue)); System.out.println(&quot;referenceQueue.size = &quot; + referenceQueue.poll()); System.gc(); Thread.sleep(1000); for (WeakReference&lt;NormalObject&gt; weakReference : weakObjList) &#123; WeakNormalObjectReference normalObjectReference = (WeakNormalObjectReference) weakReference; System.out.println(&quot;引用队列元素name： &quot; + normalObjectReference.getName()); &#125; &#125;&#125; 结果： 1234567referenceQueue.size = nullNormalObj执行finalize()NormalObj执行finalize()NormalObj执行finalize()引用队列元素name： huang引用队列元素name： qi引用队列元素name： chang","categories":[],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://example.com/tags/jvm/"}]},{"title":"Redis","slug":"Redis","date":"2021-08-17T01:59:34.000Z","updated":"2021-08-17T01:59:51.069Z","comments":true,"path":"2021/08/17/Redis/","link":"","permalink":"http://example.com/2021/08/17/Redis/","excerpt":"","text":"Memcache和Redis的区别Memcache:代码层次类似于Hash 数据类型的支持不同，Redis支持更丰富的数据类型 持久化不同，Redis支持数据的持久化，而Memecached把数据全部存在内存中 Redis支持集群，分片 Memcached过期数据的删除只用到惰性删除，而Redis同时使用了惰性删除与定期删除 Redis的数据类型：stringRedis 并没有使用 C 的字符串表示，而是自己构建了一种 简单动态字符串（simple dynamic string，SDS）。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)） 常用命令：set,get,strlen,exists,decr,incr,setex setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire) ttl key # 查看数据还有多久过期 listRedis 的 list 的实现为一个 双向链表，即可以支持反向查找和遍历 常用命令: rpush,lpop,lpush,rpop,lrange,llen 等。 hashhash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。不过，Redis 的 hash 做了更多优化。 常用命令： hset,hmset,hexists,hget,hgetall,hkeys,hvals 等。 setset 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。 常用命令： sadd,spop,smembers,sismember,scard,sinterstore,sunion 等。 sorted setsorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列， 常用命令： zadd,zcard,zscore,zrange,zrevrange,zrem 从海量Key里查询出某一固定前缀的KeyKeys pattern ： 查找所有符合给定模式pattern的key，但是该指令一次性返回所有匹配的key，key的数量过大时会发生卡顿。 SCAN cursor [MATCH pattern] [COUNT count],基于游标的迭代器，需要基于上一次游标延续之前的迭代过程，以0作为游标开始一次新的迭代，知道命令返回0完成一次遍历。不保证每次执行都返回某个给定数量的元素，支持模糊查询。返回的数据可能存在重复，因为并不是每次调用返回的游标都是递增的，需要做额外的处理。 如何通过Redis实现分布式锁分布式锁需要解决的问题 互斥性 安全性 死锁 容错 安全性指的是只有持有锁的才能释放锁，存在的一种情况是一个线程A执行程序较慢，直到时间过期还没有执行完，而此时另一线程B持有了该锁, A不能释放B持有的这把锁，否则将发生程序的错乱。 容错指 当Redis挂掉之后，还能提供分布式锁的功能 上锁实现： SET key value [EX seconds] [PX milliseconds] [NX|XX] EX seconds : 设置键的过期时间为 second 秒 PX millisecond ：设置键的过期时间为 millisecond毫秒 NX : 只有键不存在时，才对键进行设置操作 XX：只有键已经存在时，才对键进行设置操作 SET操作成功完成时，返回OK，否则返回nil 例： set locktarget 12345 ex 10 nx 主动释放锁实现： lua脚本 123456789-- lua删除锁：-- KEYS和ARGV分别是以集合方式传入的参数，对应上文的Test和uuid。-- 如果对应的value等于传入的uuid。if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then return redis.call(&#x27;del&#x27;, KEYS[1]) else return 0end 上述在单机环境下可以很好运行，redis集群环境可以采用Redisson + RLock 参考：https://www.cnblogs.com/niceyoo/p/13736140.html 大量的key同时过期的注意事项集中过期，由于清除大量的key很耗时，会出现短暂的卡顿现象。 解决方案：在设置key的过期时间的时候，给每个key加上随机值。 Reids的删除策略 惰性删除 ：只会在取出 key 的时候才对数据进行过期检查。这样对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。 定期删除 ： 每隔一段时间抽取一批 key 执行删除过期 key 操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。 定期删除对内存更加友好，惰性删除对 CPU 更加友好。两者各有千秋，所以 Redis 采用的是 定期删除+惰性/懒汉式删除 。 如何使用Redis做异步队列使用List作为队列，RPUSH生产消息，LPOP消费消息。 缺点：没有等待队列里有值就直接消费 BLPOP key [key…] timeout : 阻塞直到队列有消息或者超时 缺点：只能提供一个消费者消费 pub/sub ： 主题订阅者模式 发送者发送者发送消息，订阅者接收消息 订阅者可以订阅任意数量的频道 缺点：消息的发布是无状态的，无法保证可达 Redis的内存淘汰机制 定期删除对内存更加友好，惰性删除对 CPU 更加友好。两者各有千秋，所以 Redis 采用的是 定期删除+惰性/懒汉式删除 。 volatile-lru（least recently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru（least recently used）：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的） allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！ 4.0 版本后增加以下两种： 7.volatile-lfu（least frequently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰 8.allkeys-lfu（least frequently used）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key Redis的持久化机制快照持久化(RDB)Redis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。 12345save 900 1 #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。save 300 10 #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。save 60 10000 #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 自动化触发RDB持久化的方式： 根据redis.conf配置里的SAVE m n 定时触发 (用的是BGSAVE) 主动复制时，主节点自动触发 执行Debug Reload 执行Shutdown且没有开启AOF持久化 当调用bgsave时，Redis fork出一个子进程，父进程负责处理client请求，子进程负责数据持久化，由于OS的copy-on-write，父子进程会共享相同的物理页面，当父进程处理写请求时，os会为要修改的页面创建副本，而不是写共享的页面，所以子进程物理页面内的数据时fork时刻的整个数据库的快照。 RDB文件的载入一般是自动的，在Redis启动中，如果发现 .rdb文件，会自动进行载入 缺点： 内存数据的全量同步，数据量大会由于IO而严重影响性能 可能会因为Redis挂掉而丢失从当前至最近一次快照期间的数据 AOF持久化与快照持久化相比，AOF 持久化的实时性更好，因此已成为主流的持久化方案。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化，可以通过 appendonly 参数开启： 1appendonly yes Redis配置文件中存在三种不同的AOF持久化方式 123appendfsync always #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度appendfsync everysec #每秒钟同步一次，显示地将多个写命令同步到硬盘appendfsync no #让操作系统决定何时进行同步 日志重写解决AOF文件大小不断增大的问题，因为AOF记录的是每次的操作指令，所以会存在很多多余的记录，通过日志重写，可以减小aof文件的体积。 RDB和AOF的优缺点 RDB优点：全量数据快照，文件小，恢复快 RDB缺点：无法保存最近一次快照之后的数据 AOF优点：可读性高，适合保存增量数据，数据不易丢失 AOF缺点：文件体积大，恢复时间长 Redis 4.0 对于持久化机制的优化Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。 如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。 补充内容：AOF 重写 AOF 重写可以产生一个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。 AOF 重写是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有 AOF 文件进行任何读入、分析或者写入操作。 在执行 BGREWRITEAOF 命令时，Redis 服务器会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新旧两个 AOF 文件所保存的数据库状态一致。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF 文件重写操作。 重写的触发方式： 手动执行 bgrewriteaof 触发AOF重写 在redis.conf文件中配置重写的条件，如： 12auto-aof-rewrite-min-size 64MB // 当文件小于64M时不进行重写auto-aof-rewrite-min-percenrage 100 // 当文件比上次重写后的文件大100%时进行重写 Redis事务可以将 Redis 中的事务就理解为 ：Redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]},{"title":"容器类","slug":"容器类","date":"2021-08-16T02:59:03.000Z","updated":"2021-08-16T02:59:37.991Z","comments":true,"path":"2021/08/16/容器类/","link":"","permalink":"http://example.com/2021/08/16/%E5%AE%B9%E5%99%A8%E7%B1%BB/","excerpt":"","text":"待： HashMap多线程的死循环问题，以及ConcurrentHashMap 是怎么解决的 HashMap源码重新阅读 Cas锁 记： ConcurrentHashMap 和 Hashtable 的区别 底层数据结构不同， ConcurrentHashMap在JDK1.8的时候跟HashMap一样，同样采用了 数组 + 链表/红黑二叉树的。Hashtable采用了数组 + 链表的结构。 实现线程安全的方式，Hashtable使用synchronized来保证线程安全。 ConcurrentHashMap 在JDK1.8之前，采用对桶数组分隔片那段的操作，每一把锁只锁一部分数据。多线程访问容器里不同数据段的数据就不会发生锁竞争。而在JDK1.8的时候，抛弃了segment的概念，而是采用Node数组+链表+红黑树的数据结构来实现，并发控制使用synchronized和CAS实现。synchronized 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，效率又提升 N 倍。 CAScas 的 ABA问题可以通过 AtomicStampedReference 解决 参考：Java并发之CAS原理分析","categories":[],"tags":[{"name":"java容器 CAS","slug":"java容器-CAS","permalink":"http://example.com/tags/java%E5%AE%B9%E5%99%A8-CAS/"}]},{"title":"SpringCloud系列-雪崩","slug":"SpringCloud系列-雪崩","date":"2021-08-09T06:56:05.000Z","updated":"2021-08-09T06:59:24.887Z","comments":true,"path":"2021/08/09/SpringCloud系列-雪崩/","link":"","permalink":"http://example.com/2021/08/09/SpringCloud%E7%B3%BB%E5%88%97-%E9%9B%AA%E5%B4%A9/","excerpt":"","text":"雪崩效应 断路器 服务容错常见解决方案 超时 限流 仓壁模式 断路器模式 使用Sentinel实现容错 轻量级的流量控制,熔断降级 Java 库 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt; 在SpringBoot整合 sentinel 后 , 会暴露出/actuator/sentinel","categories":[],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://example.com/tags/SpringCloud/"}]},{"title":"SpringCloud系列-网关","slug":"SpringCloud系列-网关","date":"2021-08-09T06:56:00.000Z","updated":"2021-08-09T06:59:19.097Z","comments":true,"path":"2021/08/09/SpringCloud系列-网关/","link":"","permalink":"http://example.com/2021/08/09/SpringCloud%E7%B3%BB%E5%88%97-%E7%BD%91%E5%85%B3/","excerpt":"","text":"Spring Cloud Gateway 是Spring Cloud的网关（第二代），未来会取代Zuul（第一代） 基于Netty、Reactor以及WebFlux构建 优点：性能强劲，功能强大 内置了很多实用的功能，比如转发、监控、限流等，设计优雅，容易扩展 缺点：依赖Netty与WebFlux，不是Servlet编程模型，有一定的适应成本。不能在Servet容器下工作，也不能构建成WAR包。不支持SpringBoot 1.X 简单使用pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.huang&lt;/groupId&gt; &lt;artifactId&gt;gatewaay&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;gatewaay&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Greenwich.SR1&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;0.9.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.yml 123456789101112131415161718192021server: port: 8040spring: application: name: gateway_huang cloud: nacos: discovery: server-addr: 81.70.229.229:8848 gateway: discovery: locator: enabled: truemanagement: endpoints: web: exposure: include: health endpoint: health: show-details: always 在gateway启动后，可以访问gateway的服务，然后拼接nacos上注册的微服务名的方式来访问微服务，例如现在有nacos上有userCenter微服务，那么就可以localhost:8040/userCenter/user/getByID/1这样访问 核心概念Route（路由）： Spring Cloud Gateway的基础元素，可简单理解为一条转发的规则。包含: ID 目标URL Predicate集合以及Filter集合。 Predicate（谓词） 即java.util.function.Predicate，Spring Cloud Gateway使用Predicate实现路由的匹配条件 Filter（过滤器） 修改请求及响应 Spring Cloud Gateway架构图 方框内的就是SpringCloud Gateway Gateway Client：指外部访问接口 Gateway Handler Mapping： 对判断请求的路径进行处理，寻找匹配的路由 Gateway Web Handler：查找该路由所配置的filter，然后依次执行过滤器 路由谓词工厂 使用详解：https://www.imooc.com/article/290804 自定义Predicate也比较简单，参考源码即可 过滤器工厂详解Spring Cloud Gateway-过滤器工厂详解（GatewayFilter Factories）：http://www.imooc.com/article/290816 调试的技巧： 断点打在 org.springframework.cloud.gateway.filter.NettyRoutingFilter#filter ，就可以调试Gateway转发的具体细节了 添加如下配置，可观察到一些请求细节： 123456logging: level: org.springframework.cloud.gateway: trace org.springframework.http.server.reactive: debug org.springframework.web.reactive: debug reactor.ipc.netty: debug 全局过滤器Spring Cloud Gateway-全局过滤器（Global Filters）：https://www.imooc.com/article/290821 SpringCloud与Sentinel的整合？？？Spring Cloud Gateway的监控https://www.imooc.com/article/290822 介绍了SpringCloud Gateway在集成actutor的一些端点 SpringCloudGateway调试排错技巧https://www.imooc.com/article/290824 过滤器执行顺序全局过滤器是有Order的，Order越小越先执行 局部过滤器也是一样，Order越小的越先执行 这种情况下 执行顺序是，先执行 default-filters下的AddRespolnseHeader再执行routes下的AddRespolnseHeader，再执行default-filters下的PrefixPath，再执行routes吓得PreLog，再执行routes下的AddRequestHeader。 SpringCloudGateway的限流https://www.imooc.com/article/290828","categories":[],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://example.com/tags/SpringCloud/"}]},{"title":"SpringCloud系列-sentinel","slug":"SpringCloud系列-sentinel","date":"2021-08-09T06:55:54.000Z","updated":"2021-08-09T06:59:09.970Z","comments":true,"path":"2021/08/09/SpringCloud系列-sentinel/","link":"","permalink":"http://example.com/2021/08/09/SpringCloud%E7%B3%BB%E5%88%97-sentinel/","excerpt":"","text":"Sentinel系统规则源码位置：com.alibaba.csp.sentinel.slots.system.SystemRuleManager#checkSystem Loadlinux系统下可以通过uptime命令查看系统负载，load averages：1.97 2.21 2.38，第一个参数代表一分钟内的系统平均负载，第二个参数代表五分钟以内的系统平均负载，第三个参数代表十五分钟以内的系统平均负载，也被分别称为 load1 load5 load 15 当系统load1(1分钟的load)超过有阈值，且并发线程数超过系统容量时触发，建议设置为CPU核心数 * 2.5。 备注：仅对Linux/Unix-like机器生效，系统容量 = maxQps * minRt ，maxQps为秒级统计出来的最大QPS，minRt：秒级统计出来的最小响应时间。 RT所有入口流量的平均RT达到阈值触发 线程数所有入口流量的并发线程数达到阈值 入口QPS所有入口流量QPS达到阈值触发 使用代码进行配置https://www.imooc.com/article/289345 sentinel控制台配置项 Sentinel APIspring.cloud.sentinel.filter.enabled=false 关闭掉对Spring MVC端点的保护，可以理解为 为false时，不会扫描接口url展示在sentinel 控制台上, 但是通过api的方式可以展示在控制台上 12345678910111213141516171819202122232425@GetMapping(&quot;/test-sentinel&quot;)public String testSentinel(String a) &#123; Entry entry = null; String resourceName = &quot;test-sentinel-api&quot;; ContextUtil.enter(resourceName, &quot;testService&quot;); try &#123; entry = SphU.entry(resourceName); if (StringUtils.isBlank(a)) &#123; throw new IllegalArgumentException(); &#125; &#125; catch (BlockException e) &#123; return &quot;限流或者降级了&quot;; &#125; catch (IllegalArgumentException e) &#123; Tracer.trace(e); return &quot;非法参数&quot;; &#125; finally &#123; if (entry != null) &#123; entry.close(); &#125; ContextUtil.exit(); &#125; return &quot;success&quot;;&#125; 在调用上面接口后，控制台只会显示这么一条数据 需要注意的时，在使用异常比例，异常数降级时，所指的异常默认是BlockException，需要指定其他异常需要调用Tracer.trace(e) 而ContextUtil的enter和exit控制的是流控规则的针对来源。 @SentinelResource详解属性详解 https://www.imooc.com/article/289384 使用注解与上面使用sentinel api实现上述不同点： Api方式实现，捕获除BlockException之外的异常需要使用Tracer.trace(),而使用注解的方式默认是捕获Throwable，Class&lt;? extends Throwable&gt;[] exceptionsToTrace() default &#123;Throwable.class&#125;; 注解的方式不支持 ContextUtil.enter()这种功能 12345678910111213141516171819@GetMapping(&quot;/test-sentinel-resource&quot;)@SentinelResource(value = &quot;test-sentinel-resource&quot;, blockHandler = &quot;blockHandler&quot;, fallback = &quot;fallbackHandler&quot;)public String testSentinelResource(String param) &#123; if (StringUtils.isBlank(param)) &#123; throw new IllegalArgumentException(&quot;param is blank&quot;); &#125; return &quot;success&quot;;&#125;public String blockHandler(String param) &#123; log.error(&quot;限流或降级&quot;); return &quot;被限流或者降级了&quot;;&#125;public String fallbackHandler(String param, Throwable ex) &#123; log.error(&quot;被降级 : &#123;&#125;&quot;, ex.getMessage()); return &quot;被降级了&quot;;&#125; 值得注意的是，在配置降级规则后 fallback回调函数中的异常为java.lang.IllegalArgumentException: param is blank blockHandler回调函数com.alibaba.csp.sentinel.slots.block.degrade.DegradeException RestTemplate整合Sentinel注解：@SentinelRestTemplate 整合的开关：resttemplate.sentinel.enabled默认为true 相关源码com.alibaba.cloud.sentinel.custom.SentinelBeanPostProcessor Feign整合Sentinel整合的开关：feign.sentinel.enabled默认为false 123@FeignClient(name = &quot;userCenter&quot;, path = &quot;user&quot;, configuration = UserCenterFeignClientConfig.class, fallbackFactory = UserCenterFeignClientFallBackFactory.class) 需要注意的是 The fallback factory must be a valid spring bean. 123456789101112131415161718@Componentpublic class UserCenterFeignClientFallBackFactory implements FallbackFactory&lt;UserCenterFeignClient&gt; &#123; @Override public UserCenterFeignClient create(Throwable cause) &#123; cause.printStackTrace(); return new UserCenterFeignClient() &#123; @Override public UserDto getByID(Integer id) &#123; return null; &#125; @Override public String paramTest(TestGetParam getParams, TestPostParam postParams) &#123; return &quot;备用信息&quot;; &#125; &#125;; &#125;&#125; 需要注意的是这里的fallback其实与@SentinelResource的fallback类似，在@SentinelResource未指定blockHandler的情况下，行为一致，相比而言@FeignClient缺少单独的处理限流的类，不过可以通过判断FallbackFactory中的Throwable类型来判断，如果为com.alibaba.csp.sentinel.slots.block.flow.FlowException则为限流，此处可利用SpringBoot的全局异常处理机制实现限流抛出统一信息，降级给出自定义信息 Sentinel扩展Api 目前使用的spring-cloud-alibaba2.2.5版本的 相关源码已不在CommonFilter中，在com.alibaba.csp.sentinel.adapter.spring.webmvc.AbstractSentinelInterceptor 配置项 : https://www.imooc.com/article/289562","categories":[],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://example.com/tags/SpringCloud/"}]},{"title":"SpringCloud系列-feign","slug":"SpringCloud系列-feign","date":"2021-08-09T06:55:49.000Z","updated":"2021-08-09T06:58:57.079Z","comments":true,"path":"2021/08/09/SpringCloud系列-feign/","link":"","permalink":"http://example.com/2021/08/09/SpringCloud%E7%B3%BB%E5%88%97-feign/","excerpt":"","text":"Feign Netflix开源的声明书HTTP客户端 Feign组件 Feign.Builder : 构建每一个FeignClient Client :需要注意的是 feign.Client.default未使用连接池, 而LoadBalancerFeignClient在默认情况下可以看做是具有负载均衡功能的FeignClient 自定义Feign日志级别 Java配置类的方式指定通过注解在FeignClient的@FeignClient的configuration属性中所配置Logger.Level类进行指定 1234@FeignClient(name = &quot;userCenter&quot;, path = &quot;user&quot;, configuration = UserCenterFeignClientConfig.class)public interface UserCenterFeignClient &#123; ...&#125; UserCenterFeignClientConfig.java 1234567public class UserCenterFeignClientConfig &#123; @Bean public Logger.Level level() &#123; return Logger.Level.FULL; &#125;&#125; 配置属性的方式进行指定1feign.client.config.userCenter.logger-level = full Feign的全局配置 Java代码方式 配置属性方式 Java代码方式1@EnableFeignClients(defaultConfiguration = CustomDefaultFeignClientConfig.class) 123456public class CustomDefaultFeignClientConfig &#123; @Bean public Logger.Level level() &#123; return Logger.Level.FULL; &#125;&#125; 配置属性方式1feign.client.config.default.logger-level = full 支持的配置项Java代码方式支持的 配置属性方式支持的 Ribbon配置与Feign配置 Feign性能优化 连接池 日志级别 连接池1234&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt;&lt;/dependency&gt; 1feign.httpclient.enabled=true Feign常见问题总结","categories":[],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://example.com/tags/SpringCloud/"}]},{"title":"SpringCloud系列-ribbon","slug":"SpringCloud系列-ribbon","date":"2021-08-09T06:55:37.000Z","updated":"2021-08-09T06:59:04.102Z","comments":true,"path":"2021/08/09/SpringCloud系列-ribbon/","link":"","permalink":"http://example.com/2021/08/09/SpringCloud%E7%B3%BB%E5%88%97-ribbon/","excerpt":"","text":"Ribbon 客户端负载均衡器 Ribbon的依赖在nacos的依赖中已经存在 简单使用： 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 注解@LoadBalanced 12345@Bean@LoadBalancedpublic RestTemplate restTemplate() &#123; return new RestTemplate();&#125; 使用RestTemplate进行访问 1restTemplates.getForObject(&quot;http://userCenter/user/getByID/&#123;id&#125;&quot;, String.class, id); userCenter为service名称，RestTemplate在进行访问时对其进行替换来实现客户端负载均衡 ​ Ribbon内置的负载均衡规则 默认的是ZoneAvoidanceRule,Zone是机房的含义,在没有机房设置的情况下,相当于RoundRobinRule 细粒度配置自定义 可以根据service的不同设置不同的规则 Java代码配置 配置属性配置 Java代码配置RibbonUserCenterConfig.java 123@RibbonClient(name = &quot;userCenter&quot;,configuration = RibbonConfiguration.class)public class RibbonUserCenterConfig &#123;&#125; RibbonConfiguration.java 12345678@Configurationpublic class RibbonConfiguration &#123; @Bean public IRule randomRule() &#123; return new RandomRule(); &#125;&#125; @RibbonClient的name属性为服务名，RibbonConfiguration属性指的是调用该服务时所使用的配置类 需要注意的是配置Ribbon组件的配置类不能被Spring容器扫描到，否则会成为全局的一个配置类，这是个父子上下文的问题。在实际运用中，应尽量避免上下文重叠的情况出现， 实现ribbon全局配置 123@RibbonClients(defaultConfiguration = RibbonConfiguration.class)public class RibbonUserCenterConfig &#123;&#125; 配置属性方式 饥饿加载默认情况下，Ribbon是懒加载的。即RestTemplate第一次访问`http://userCenter/user/geByID/1`时才会创建一个userCenter的RibbonClient。 通过下面配置打开饥饿加载 123ribbon.eager-load.enabled=true#为哪些client打开饥饿加载ribbon.eager-load.clients=userCenter,service1 **","categories":[],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://example.com/tags/SpringCloud/"}]}],"categories":[],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://example.com/tags/jvm/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"},{"name":"java容器 CAS","slug":"java容器-CAS","permalink":"http://example.com/tags/java%E5%AE%B9%E5%99%A8-CAS/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://example.com/tags/SpringCloud/"}]}